우리는 DL이 무엇인지 대한 분명한 정의는 알지 못함
DL은 다층의 연산 유닛을 사용하는 머신러닝 알고리듬의 한 종류로, 각 층은 데이터에 대한 그 자신만의 표현을 학습한다.
이러한 표현은 그 뒤의 층 layer에 의해 조합됨
이 정의는 특히 층 및 연산 유닛의 개념을 아직 설명하지 않았따는 점에서 다소 추상적이지만 처음 몇 개 장에서 이것이 무엇을 뜻하는지를 보여주는 구체적인 예시를 제공하는 것임

DL의 근본적인 부분 중 하나는 생물학의 신경세포 neuron 와 이름이 같으면서 이로부터 영향을 받은 심층 신경망 DNN Deep Neural Network임
DL 안의 기법들이 뇌의 활동을 얼마나 밀접하게 흉내 내는지에 대한 논쟁이 지속되고 있는 가운데, 한 무리는 신경망이란 용어를 사용한다는 점에서 DL이 뇌보다 더 발전되었음으로 보여준다고 주장함
이에 따라 이들은 인공 뉴런 artificial neuron이란 용어 대신 유닛 unit을, 신경망 neural network 대신에 네트워크를 사용하기를 권장한다. 의심할 바 없이 DL 및 인공지능 분야는 주류 미디어에서 상당히 과장돼왔다 
책을 읽고 나면 DL이 어떤 종류의 문제르 ㄹ해결할 수 있는지에 대한 더욱 정확한 시각을 갖게 될 것임
신경망과 뉴런 이란 단어를 자유롭게 사용하기로 했지만 보여주는 알고리듬은 실제 인간 뇌가 어떻게 동장하는지 보다는 기계의 능력에 더 연관되어 있음을 인식하기 바람

DNN(심층신경망)은 DL의 부분집합이고, DL은 ML 분야의 부분집합이고, 이는 AI라는 더 큰 분야의 부분집합니다.
DL의 정확한 정의 및 경계에 너무 많이 집중하지 않음
ML이나 AI의 다른 분야에 자세히 들어가지 않기로 함
대신에 DNN이 무엇인지에 대한 설명과 이를 적용할 수 있는 과제의 유형에 집중한다.

## 심층신경망의 간략한 역사
네트워크 아키텍처는 이후 이야기함
지금은 네트워크를 입력과 출력이 있는 불투명한 시스템이라 생각해도 충분함
사용하는 모델은 무언가를 나타내기 위한 것으로 이미지나 텍스트열을 네트워크의 입력으로 그리고 네트워크는 이미지가 무엇을 지니고 있는지에 대한 해석 아니면 다른 언어로의 자연어 번역과 같이 무언가 유용한 것을 출력으로 만들어낸다.

앞서 언급했듯 신경망의 중심 부분은 인공뉴런이다.
처음 학습 알고리듬은 다층 네트워크를 포함하지 않았음 일반적인 내러티브(=서사)에 따르면 신경망이 유행에 뒤떨어지게 만들었다.

올리자란 - 민스키와 파퍼트의 선언이 잘못됐는지를 연구
슈미드후버 - 민스키와 파퍼트의 책이 출간되기 4년 전에 다수준 네트워크를 위한 학습 알고리듬이 존재했음을 지적함

신경망의 두번째 물결은 1980년대 시작됨
다층 네트워크의 자동 학습을 위한 역전파 알고리듬을 설명한 논문으로부터 크게 영향을 받았다.
루멜하트와 동료들은 이 알고리듬이 퍼셉트론의 한계를 극복하는데 사용될 수 있음을 보였다.
이 논문이 민스키와 파퍼트가 제기한 우려를 다룬다고 믿는다는 점을 직접적으로 지적했다.
루멜하트와 동료들은 신경망의 측면에서 역전파 알고리듬을 대중화했겠지만
이 알고리듬이 논문에서 나온 것이 이것이 처음은 아님
웨어보스는 1981년에 이를 신경망 측면에서 설명했음

신경망 연구의 두 번 째 물결에서 중요한 성과는 1989년 LeNet의 개발 CNN(합성곱 신경망)
손글씨 우편번호를 인식할 수 있음을 보여줬다. LeNet은 첫 번째로 발표된 CNN이라 믿어지는 후쿠시마의 Neocognitron(네오코그니트론)을 바탕으로 만들어졌다.
LeNet의 향상된 버진은 나중에 미국 주요 은행들에서 손글씨 수표를 읽는데 쓰였고 신경망이 처음으로 크게 상업적으로 응용된 사례중 하나이다.
이러한 발전에도 신경망은 또다시 유행에 뒤처졌고 이유는 당시의 제한적인 연산 능력이 네트워크가 더 큰 문제로 확장되는 것을 막았기 때문
전통적인 ML 접근법이 더 나은 대안이라 여겨졌기 때문

신경망 연구의 세 번째 물결은 알고리듬적인 발전, 막대한 데이터셋의 가용성 그리고 일반적인 몸ㄱ적의 연산을 위한 그래픽 처리 유닛의 사용 능력이 조합되면서 가능해졌음
외부자의 시각에서는 2012년에 나왔고 이 분야가 DL로 리브랜딩 되었으며 AlexNet 덕분에 크게 대중화되었음
이는 ImageNet이라 알려진 컴퓨터 비전 시합에서 다른 참여자보다 훨씬 높은 점수를 받은 CNN이였음
1990년대와 2000년대의 처음 10년 동안 신경망 연구를 계속 수행한 끈질긴 연구 그룹 덕분에 가능했음
2006년 심층 네트워크 라는 용어를 사용하기 시작했고
ImageNet 시험은 일부 GPU 가속을 사용한 신경망이 전통적인 기술을 이긴 첫 번째 대회가 아니였음
그레이브스와 동료들은 2009년에 손글씨 인식에서 신경망으로 시합에서 승리함
마찬가지로, 시레산과 동료들은 2011년 GPU 가속된 네트워크를 이미지 분류에 사용했음

> 책에서 달리 논의하지 않거나 살펴보지 않아도 언젠가는 배워야 한다고 생각하는 것들의 강조는 노란색임
> 노란색은 새로운 주제를 배우는 데 있어 일부 기본 스킬만을 얻는 것이 아니라 다음 단계가 무엇인지 알아야하는 인사이트를 제공해주는 부분

이 책은 DL 분야의 가장 최근의 발전되 기법 모두를 자세히 설명하는 것을 목표로 하지 않음 대신에 최신 발전을 이해하는데 필수적이라 생각하는 개념과 기법을 포함한다.
주요 아키텍처가 이러한 개념 위에서 만들어지는지 설명하지만 더욱 나은 아키텍처가 나타날 것이 거의 확실하다.
더욱 최근의 논문을 읽음으로써 학습을 계속하도록 충분한 지식을 제공하는 것임
특히 흥미로운 점을 발견한 주제에 대해 더 알아볼 수 있도록 이 책 전체에 걸쳐 참조를 흩어놓기로 결정하였고
책에서 설명을 따라갈 때 참조를 찾아볼 필요는 없음

알고리듬 감사의 출현으로, 연구자가 상용 시스템에서의 인간 편향 및 다른 관측된 문제를 인식하고 보고한다. 연구자는 이러한 문제를 완화하기 위해 알려진 편향 및 배포된 어떤 시스템이든지 의도된 사용 사례를 문서화할 것을 제안함. 이는 시스템을 만들기 위해 사용된 데이터 및 배포된 DL 모델 모두에 적용된다. 토마스는 윤리적 문제를 피하기 위해 프로젝트 과정 동안 DL 모델 모두에 적용된다. 토마스는 윤리적 문제를 ㅎ피하기 위해 프로젝트 과정 동안 DL실무자를 지도하도록 질문 체크리스트를 제안한다.

## DL 프레임워크 선택하기
DL의 실무자로서 어떤 DL 프레임워크를 사용할지 정해야 한다.
DL 프레임워크는 DL 모델을 구현할 때 저수준의 세세한 부분을 다루는 기능을 제공한다.
DL 분야가 빠르게 변하는 것처럼 다른 프레임워크도 그러하다.
본격적인 프레임워크 중 가장 인기있는 것은 텐서플로와 파이토치라는 인상을 받음
텐서플로는 케라스 API를 자체적으로 지원하고 다른 중요한 프레임워크는 MXNet임
이러한 프레임워크 중 하나로 개발된 모델은 TensorRT 추론 엔진을 사용해 배포할 수 있다.

중요하다고 여기는 분야
책을 따라가는데 필요한 최소한의 지식 모음

### 통계와 확률론
많은 DL문제는 정확한 답이 없으므로 확률론이 중심 테마가 됨
얼마나 확신하는지와 같은 불확실성이 주로 개입됨
통계와 확률에 대한 깊은 지식을 필요로 하지 않음
산술 평균을 계산하고 확률의 기본 개념을 이해할 수 있기를 기대하며, 분산 및 확률변수를 어떻게 표준화하는지 알고 있다면 도움이 되겠지만 꼭 필요한 것은 아니다.

### 선형대수학
DL의 기본 토대는 변수의 가중합 계산에 기반하며, 이는 많은 덧셈과 곱셈이 필요함을 암시한다.
선형대수는 이러한 계산을 간결한 방식으로 설명할 수 있게 해주는 수학 분야임
이 책은 벡터와 행렬을 포함하는 공식을 자주 구체화한다.
계산에는 다음이 수반됨
- 내적 dot projuct
- 행렬-벡터 곱
- 행렬-행렬 곱
과거에 이러한 개면을 본적이 없다면 이 책을 따라가기 위해 해당 내용을 배울 필요가 있음

### 미적분
DL의 학습부분은 loss function 혹은 error function로 알려진 함숫값의 최소화를 기본으로 함
loss function을 최소화 하는데 사용된 기법은 미적분학의 다음 개념들임
- 단일 변수 함수의 미분을 계산
- 다변수 함수의 편미분을 계산
- 미적분학의 연쇄법칙을 사용해 미분을 계산

### 제약 혹은 비제약 최적화를 위한 수치적 방법
DL에서 손실 함수의 최소화를 시도할 때 해석적인 해를 찾는 것은 통상적으로 가능하지 않다. 대신 수치적 최적화법에 의존한다. 가장 널리 알려진 방법은 경사 하강법 gradient descent라 알려진 반복법이다. 여러분이 반복법 및 연속 함수에서 극점을 찾는 것에 관한 무언가를 이미 알고 있다면 도움이 될 것이다. 그러나 경사 하강법에 대한 사전지식은 필요로 하지 않으며, 사용하기 전에 어떻게 동작하는지는 3장에서 소개한다.

### 파이썬 프로그래밍
일반적인 프로그래밍에 대한 일정한 지식 없이는 특정한 DL 애플리케이션 외에 어떠한 것도 하기가 어렵다. 게다가 인기 잇는 DL프레임워크가 파이썬에 기반하므로 무언가를 시도하고 코드 예제를 수정할 수 있도록 적어도 기본적인 파이썬 스킬은 갖출 것을 권한다.
프로그래밍 주제를 다룬 좋은 책은 많이 있음 기본적인 프로그래밍 스킬이 있따면 python.org 튜토리얼을 따라가는 것만으로도 상대적으로 쉽게 파이썬을 쉽게 시작할 수 있을 것임
DL스킬을 실제로 적용하고자 한다면 기본적인 파이썬 프로그래밍을 배워야 한다. 
객체 기반 프로그래밍 구성체를 거의 혹은 아예 사용하지 않는다. 자주 사용되는 특정 모듈로 넘파이가 있고 이는 여러가지 모듈 중에서도 벡터와 행렬용 데이터 타입을 제공한다. 다차원 데이터를 조작하는데 판다스를 사용하는것이 일반적이지만, 책에서는 사용하지 않음
- 정수와 부동소수점 데이터 타입
- 리스트와 딕셔너리
- 외부 패키지 불러오기와 사용하기
- 넘파이 배열
- 넘파이 함수
- if, for, while
- 함수를 정의하고 부르기
- 텍스트열과 수치적 데이터 타입을 출력하기
- matplotlib으로 데이터 그리기
- 파일을 읽고 쓰기
많은 프로그래밍 예제가 DL 프레임워크가 제공하는 구성체에 의존한다. 이러한 프레임ㅁ워크를 미리 알 필요는 없지만 기능은 코드 예제의 설명에서 서서히 소개한다. 코드 예제가 책을 따라 점차적으로 어려워지므로 코딩 초심자라면 시간 일부를 써서 책을 익는 것과 더불어 코딩 스킬을 연마할 필요가 있다.

#### 데이터 표현
상당수의 DL 기법은 고도로 최적화된 ML프레임워크로 다룬다. 여러분은 입력 데이터를 먼저 이러한 프레임워크가 소비할 수 있도록 적절한 형식으로 변환해야 한다. 그러므로 사용할 데이터의 형식, 언제 적용 가능한지, 어떻게 더 적절한 형식으로 변환할 수 있는지 어느정도 알 필요가 있다. 
이미지에서 RGB 표현의 기본으로 알면 도움이 된다.
마찬가지로 텍스트를 입력 데이터로 사용하는 경우 글자가 어떻게 컴퓨터로 표현되는지 알면 도움이 되고
일반적으로 원본 데이터는 저품질인 경우가 많으므로 정리하는 방법에 대해 어느정도의 인사이트를 알면 좋다.
결측되거나 중복된 데이터 항목, 다른시간대로부터 나온 타임스탬프 수동처리에 의한오타를 자주 발견하게 될 것이다. 책의 예제에서는 이것이 통상적으로 문제가 안되지만 프로덕션 설정에서는 알 필요가 있다. 