data : 데이터셋이 다운로드돼야 할 디렉터리
stand_alone : DL 프레임워크가 필요 없는 코드 예제를 포함하는 디렉토리
tf_framework : 텐서플로 프레임워크에 의존하는 코드 예제를 포함하는 디렉토리
pt_framework : 파이토치 프레임워크에 의존하는 코드 예제를 포함하는 디렉토리

tf 와 pt는 일대일 매칭된다.

각 코드 예제는 cXeY_DESCRIPTION.py 패턴을 따름
X는 장수 Y는 해당 장에서의 예제번호
DESCRITION은 예제가 무엇을 하는지에 대한 간단한 설명

DL 알고리듬의 확률적 특성으로 인해 결과는 실행마다 다를 수 있다. 

### 보조 스프레드 시트
최상단 수준의 디렉토리 설명과는 별개로 리포지토리의 루트는 network_example.xlsx라는 이름의 스프레드 시트로 포함한다.
탭은 3개가 있고 각각은 초기 장들의 특정 절에 해당함

perceptron_learning : 1장 로젠블랫 퍼셉트론의 퍼셉트론 학습 알고리듬 절에 해당함
backprop_learning : 3장 시그모이드 뉴런과 역전파 의 역전파를 사용해 기울기 계산하기 절에 해당함
xor_example : 3장의 '프로그래밍 예제: XOR 함수 학습하기' 절에 해당한다.

## 데이터 셋
프로그래밍 예제 대부분은 다양한 데이터 셋 혹은 다른 자원에 접근해야함
#### MNIST
[데이터베이스](http://yann.lecun.com/exdb/mnist)에서
- tran-images-idx3-ubyte.gz
- train-labels-idx1-ubyte.gz
- t10k-images-idx3-ubyt.gz
- t10k-labels-idx1-ubyte.gz
다운로드 후 data/mnist/ 디렉토리에 gunzip 하기
파이썬 피키지 idx2numpy가 필요함 이패키지는 모든 플랫폼에서 사용 가능한 것은 아님

#### 인구조사국의 서점 매출 데이터
[매출 데이터](https://www.census.gov/econ/currentdata)에서 얻을 수 있음
Monthly Retail Trade and Food Services - Submit
Not Seasonally Adjusted - GET DATA
데이터 값으로 된 테이블이 나오면 TXT 링크를 클릭해 CSV(Comma-Separated Values)파일을 다운로드
다운로드한 파일에서 처음 몇 줄을 지워 파일이 Period, Value라는 제목을 갖는 한 줄로 시작해 각 월을 위한 줄이 따라오게 하라. 

#### 프로젝트 구텐베르크의 프랑켄슈타인
[메리 셸리의 Frankenstein](https://www.gutenberg.org/files/84/84-0.txt)에서 다운로드 가능하다.
파일이름을 frankenstein.txt라 바꾸고 data 디렉토리에 복사하기

#### GloVe 단어 임베딩
[GloVe 단어 임베딩 파일](http://nlp.stanford.edu/data/glove.6B.zip)은 크기가 1GB에 가까움
다운로드 후 압축을 풀고 glove.6B.100d.txt 파일을 data 디렉토리에 복사

#### ANKI 이중언어 문장 쌍
[Anki 이중언어 문자 쌍](http://www.manythings.org/anki/fra-eng.zip) 다운로드 후 압축을 풀고 fra.txt를 data 디렉토리에 복사

#### COCO
data 디렉토리에 coco라는 디렉토리 만들고 파일 [다운로드](http://images.cocodataset.org/annotations/annotations_trainval2014.zip)
압축을 풀고 captions_train2014.json파일을 coco 디렉토리에 복사 13GB [파일 다운로드](http://images.cocodataset.org/zips/train2014.zip)
이를 data/coco/ 디렉토리에 압축을 풀면 압축이 풀린 디렉토리의 경로는 data/coco/train2014/ 가 됨

## DL 프레임워크 설치하기
텐서플로와 파이토치를 설치하는 방법은 여러 가지가 있고 어느정도는 사용하는 플랫폼에 따름
- 시스템 설치
- 가상환경 설치
- 도커 컨테이너 실행
- 클라우드 서비스 사용하기

텐서플로 2.4와 파이토치 1.8.0에서 테스트 함 - 바뀐부분 있을거임 
### 시스템 설치
프레임워크 및 의존하는 어떠한 패키지/라이브러리든지 시스템에 설치하고 운이 좋으면 단순한 일이지만 운이 나쁘면 이미 설치된 라이브러리가 잘못된 버전을 갖고 있기 때문에 문제에 부딪힐 수 잇음
적절한 버전으로 업그레이드 혹은 다운그레이드를 결정할 수 있지만 이는 시스템의 특정한 설치 버전에 의존하는 소프트웨어 일부를 망가뜨릴 수도 있음

가상환경에서 pip install tensorflow\==2.4
pip install torch\==1.8.0 torchvision\==0.9.0 
프레임워크 설치에 따라 나오는 오류 메시지에 주의를 기울이기 오류 메시지는 없는 패키지에 대한 의존성 혹은 이미 설치된 패키지가 잘못된 버전을 갖고 있음을 나타낼 수 있음
GPU 가속은 나중에 신경 쓸수도 있음

### 도커 컨테이너
도커 컨테이너를 사용하는 것임 이는 프레임워크를 모두 함께 설치하는 과정을 피하는 방법임
대신 먼저 시스템에 도커 엔진을 설치해야하고 그 뒤 필요한 모든 것이 이미 이미지에 설치된 도커 이미지를 다운 받는다. 그 다음 도커 엔진에게 잉미지를 바탕으로 도커 컨테이너를 만들 것을 지시함
도커 컨테이너는 가상 머신과 다소 비슷하게 그 안에 실행되는 소프트웨어를 환경으로부터 격리시킨다. 그러나 이는 운영체제 자체를 포함하지 않으므로 무게가 더 가벼움
도커 컨테이너의 사용은 DL 프레임워크를 실행하는 인기 있는 방법이고 아마도 시스템의 GPU를 활용하도록 설정하는 가장 단순한 방법일 것임

## 파이토치와 텐서플로의 주요 차이점
파이토치와 텐서플로의 주요한 차이점
전반적으로 파이토치 vs 케라스 API로 된 텐서플로의 프로그래밍 경험을 비교할 때 차이점이 하나의 주요한 그리고 하나의 중요하지 않는 범주에 속한다는 것
케라스 API에 의해 다뤄지는 무언가를 파이토치에서는 명시적으로 다뤄야 한다는 것임
초심자의 시작을 약간 어렵게 만들지만 다져진 길을 약간 벗어나고자 할 때 유연성을 제공한다는 측면에서 장기적으로 보상을 줌
### 여러분만의 FIT/TRAINING 함수를 작성해야할 필요성
파이토치에서의 가장 큰 장애물 중 하나는 모델 휸련을 위해 여러분만의 함수를 작성해야 한다는 점임 텐서플로에서 모델을 정의하면, 단순히 적절한 매개변수로 fit() 함수를 호출하고 프레임워크가 포워드 패스 및 백워드 패스 실행, 가중치 조정 등 많은 세부 사항을 다룸. 추가로 이는 손실과 정확도 같은 여러 유용한 지표를 훈련 집합 및 테스트 집합 모두에서 인쇄해줌
파이토치는 이러한 체계를 직접 다뤄야함
이는 번잡 해보일 수 있지만 실제로 많은 코드를 쓸 필요는 없음. 추가로 코드 예제에서 보여주듯. 많은 모델에서 재사용할 수 있는 여러분만의 라이브러리 함수를 간단히 쓸 수 있음
우리가 시작할 때 파이토치가 텐서플로보다 약간 더 어렵다고 생각하는 주된 예시
이러한 코드 조각을 쉽게 수정할 수 있는 강력함
훈련 루프의 텐서플로 구현이 다소 난해했던 자연어 번역 예제와 이미지 캡셔닝 예제에서 보여줌
여러분만의 훈련 루프 작성의 이 부분으로, 다음 단계를 포함시켜야 할 것이다.
- 선택한 옵티마이저에 zero_grad() 메서드를 호출해 옵티마이저에 모든 기울기를 0으로 재설정 할 것을 지시함. 왜냐하면 여러 단계에서 기울기를 누적하는 것이 기본이기 때문임
- Module 객체의 인스턴스를 호출하면 이는 forward() 메서드의 호출이 되어 포워드 패스가 된다.
- 손실을 계산하고 backward()를 호출해 백워드 패스를 진행한다.
- 선택한 옵티마이저에 step() 메서드를 호출해 현재 기울기를 바탕으로 가중치를 업데이트 한다.

포워드 패스, 손실 계산, 백워드 패스, 가중치 조정을 명시적으로 다루는 것을 제외하고, 또한 훈련 및 테스트 데이터를 미니배치로 나누는 기능을 구현해야 한다. 이는 통상적으로 DataLoader 객체로 수행한다. 케라스 API로 텐서플로를 사용할 때는 이 기능들 모두 fit() 함수가 다룬다.

### 넘파이와 파이토치 사이의 명시적 데이터 이동
텐서플로의 케라스 API는 텐서의 표현으로 넘파이 배열을 사용한다. 예를 들어 모델에 넘길 때, 형식은 다차원 넘파이 배열의 형태를 가질 것으로 기대한다. 반대로 파이토치에서 넘파이 배열과 파이토치 텐서 사이에 데이터 변환을 명시적으로 해야한다.
파이토치는 정보를 계속 추적하여 파이토치 텐서에서 자동적인 미분을 가능하게 한다.
즉, 파이토치 텐서로 작업하는 한, 함수를 정의할 때 텐서 데이터 타입이 지원하는 모든 연산을 사용할 수 있으며, 나중에 자동으로 함수의 편도함수를 계산할 수 있다. 텐서로부터 그리고 텐서로의 명시적 이동은 파이토치가 이 기능을 어떤 변수에 제공할지 추적할 수 있게 해준다.
- from_numpy()는 넘파이 배열을 파이토치 텐서로 변환한다.
- numpy()는 파이토치 텐서를 넘파이 배열로 변환한다.
- detach()는 파이토치 텐서를 만든다. 이는 저장소를 본래 파이토치 텐서와 공유하지만 자동 미분이 지원되지 않는다.
- clone()은 파이토치 텐서로부터 파이토치 텐서를 만들지만 두 텐서 사이에 저장소를 공유하지 않는다.
- item()은 파이토치 텐서에서의 요소 하나를 넘파이값으로 변환한다.
- torch.no_grad()로 이 생성자의 스코프 내 자동 미분의 지원을 끈다.
초심자에게는 이러한 함수 및 생성자가 어떻게 모두 연관되어 있는지 이해하기가 어려울 수 있으며 특히detach().clone().numpy()와 같은 조합문을 만날 때 그러할 것임
다른 것들과 마찬가지로 익숙해지는데 시간이 조금 걸리겠지만, 이해를 하면 그리 복잡하지 않을 것임

#### CPU와 GPU 사이의 명시적 데이터 전송
넘파이와 파이토치 사이의 명시적인 데이터 이동에 더해서, CPU와 GPU 사이에서 반드시 명시적으로 데이터를 이동해야 한다. 이는 다음 두 함수를 사용해 수행한다.
- to(DEVICE)는 데이터를 특정 장치로 이동한다.(보통 GPU로)
- cpu() 는 데이터를 CPU로 이동한다.
의견상 익숙해지기 쉽지만 처음에는 여전히 여러분을 힘드렉 할 수도 있음
앞서 제공했던 메커니즘과 조합될 때 그리고 .cpu().detach().numpy()와 같은 조합문을 만날 때 특히 그러함

#### 훈련과 추론의 명시적 구별
Dropout과 BatchNormalization 같은 몇몇 층 형태는 훈련 동안 추론과 다르게 움직인다. 텐서플로는 훈련(fit) 추론(predict)을 명시적인 함수가 존재하므로 자동으로 이를 다룬다. 앞서 설명했듯이 파이토치에서는 반드시 이 함수를 직접 작성해야 한다. 그러므로 여러분의 모델에 훈련용인지 추론용인지도 말을 해줘야 하는데, 다음 함수로 수행한다.
- train()은 모델을 훈련 모드로 설정한다.
- eval()은 모델을 추론 모드로 설정한다.

초심자는 eval()과 앞서 설명한 no_grad()의 기능을 혼동하기 쉬울 수 잇다. 둘 다 추론 동안 사용하는 것은 맞다. 차이점은 eval()이 올바른 움직임을 얻는 데 필요한 한편, no_grad()는 자동 미분(추론 동안 필요x)에 필요한 추가 상태를 추적하지 않는다.

#### 시퀀셜 대 평셔널 API
사소하지만 알아두면 좋은 차이점
텐서플로 프로그래밍예제에는 케라스 시퀀셜 API를 사용함
파이토치는 nn.Sequential 클래스가 매우 비슷한 개념을 갖는다.
덩구 발전되 프로그래밍 예제에서는 약간 다름. 텐서플로에서는 층을 선언하는 과정과 이들을 한데 연결하는 과정이 분리된 케라스 펑셔널 API를 사용한다. 파이토치에서는 대신에 nn.Module 클래스를 상속하고 forward()함수를 오버라이딩하는 맞춤 모델을 만들어 다른 방식으로 다룬다.

두 방법론 모두 지원하는 층의 형태를 사용할 때는 복자도 수준이 비슷하지만, 프레임워크가 내재적으로 지원하지 않는 층을 구현할 때는 파이토치 방법론이 다소 더 단순할 수도 있다
어텐션 층의 기능을 파이토치 버전으로 구현하는 16장의 프로그래밍 예제가 그 예임
텐서플로가 어텐션 층을 제공하는 한편 파이토치는 그렇지 않다는 점에서 또 다른 작은 차이를 드러냄

#### 컴파일 기능의 부재
텐서플로에서는 fit() 함수를 호출해 훈련하기 전에, compile() 함수를 호출해 손실 함수와 옵티마이저를 선택해야만 한다. 파이토치에서는 여러분만의 훈련 루프를 작성한다는 사실에 따라 그럴 필요가 없음, 이러한 과정의 입루보서, 여러분은 명시적으로 여러분만의 손실함수와 옵티마이저를 호출해야 하므로 프레임워크에게 처음부터 무슨 함수를 쓸지 말할 필요가 없음

#### 순환 층과 상태 다루기
순환층(LSTM)에서 텐서플로와 파이토치의 주요한 차이점이 두 가지 잇음
첫째 파이토치에서 LSTM 층의 적층은 복수의 인스턴스를 서로의 다음에 선언하는 대신에 간단히 LSTM 층의 적층은 복수의 인스턴스를 서로의 다음에 선언하는 대신에 간단히 LSTM층 생성자에 매개변수를 제공해 수행할 수 있다.
둘째, 순환 층을 사용하는 프로그래밍 예제에서 텐서플로가 어떤 식으로 상태가 있는 순환 층을 아니면 그렇지 않은 순환 층을 선언하는 기능을 갖는지 보여줬으며, 자동회귀 모델을 구축할 때 이를 활용 했다. 파이토치에는 상태 개념이 명시적으로 존재하지 않지만, 프로그래밍 예제의 파이토치 버전에서 이를 모방하는 방법을 보여준다.

#### 교차 엔트로피 손실
교차 엔트로피 손실 구현에서 파이토치와 텐서플로를 비교할 때 두 가지 주요한 ㅈ차이 점이 있다. 첫째, 파이토치에서 교차 엔트로피 손실 함수는 또한 암묵적으로 마지만 뉴런의 로지스틱 시그모이드 함수를, 아니면 다중클래스 분류 문제에서 소프트맥스를 모델링한다. 즉, 네트워크를 정의할 때 활성 함수도 정의하는 대신에 선형 출력 유닛을 사용해야 한다. 둘째, 파이토치에서 교차 엔트로피 손실함수는 원핫 인코딩된 목표 대신에 정수 목표를 기대한다. 즉, 목푯값을 원핫 인코딩할 필요가 없다. 이는 메모리 사용 측며에서 더욱 효율적인 구현을 야기한다.
만이 여러분이 텐서플로를 사용한다면, 같은 움직임을 얻도록 하는 옵션이 존재하지만 기본 움직임이 다르므로 이들을 명시적으로 지정해주어야 한다.

#### view/reshape
넘파이는 넘파이 배열의 차원을 바꾸는데 쓰이는 reshape()함수를 제공하며, 텐서플로에는 텐서의 모양을 바꾸기 위한 해당 함수가 있다. 파이토치는 view()라는 이름의 함수로 같은 종류의 기능을 구현한다.

