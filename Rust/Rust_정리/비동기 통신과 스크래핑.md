웹사이트에서 임의의 정보를 스크래핑하는 프로그램을 만들어보기
스크래핑 처리를 위해 반드시 알아야 할 비동기 처리에 대해서도 설명한다.

## 자주 쓰는 도구를 러스트로 만들기
프로그래밍에 빨리 숙달된려면 직접 프로그램을 만들어보는 것이 가장 좋다.
자주 쓰는 도구를 러스트로 만들어보자. 여기서는 간단한 웹 스크래핑 도구를 만들어본다.
웹 스크래핑(scraping)은 웹 사이트에 공개된 정보 중 원하는 정보를 가공해서 가져온다. 웹 크롤링(crawling)과의 차이는 특정 페이지에서 특정 데이터를 추출하느냐, 웹사이트를 직접 돌아다니며 정보를 수집하느냐의 여부다.
스크래핑은 지정한 특정 웹 페이지의 데이터를 추출하는 것이다.

## 비동기 처리
스크래핑 도구를 만들기 전에 비동기 처리에 대해 알아보자. 비동기 처리는 5장의 웹 프로그램 개발에도 나왔지만 프레임 워크를 이용했기 때문에 자세히 다루진 않았음
러스트의 비동기 처리에 대해 알아본다.
'비동기 처리'의 반대는 '동기 처리'다. '동기 처리'는 프로그램을 순차적으로 실행한다. 작성된 순서대로 실행되므로 직관적으로 이해할 수 있다는 특징이 있다.
하지만 네트워크 처리와 같이 입출력(IO)에 시간이 걸리는 처리를 수행하는 경우 데이터를 받는 동안에는 데이터 수신만을 기다려야 한다. 데이터 수신이 끝나지 않으면 다음 프로세스로 갈 수 없기 때문이다. CPU나 기타 PC 자원에 여력이 있어도 처리 완료를 기다릴 뿐이다. 수신 처리가 완료돼야만 다음 프로세스가 시작된다. 이것이 '동기 처리'다.
반대로 '비동기 처리'는 네트워크 처리와 같이 IO에 시간이 걸리는 처리를 실행할 때 처리가 완료될 때까지 기다리지 않는다. 네트워크에서 데이터를 수신하고 있어도 종료를 기다리지 않고 다른 처리를 실행한다. 그리고 수신이 완료되면 그 데이터를 처리하는 프로그램을 실행한다.

네트워크 프로그램에서 '비동기 처리'를 사용하는 이유는 이와 같이 대기 시간에도 별도의 작업을 수행하는 등 프로그램의 효율이 좋기 때문이다.

## 러스트의 비동기 처리
러스트에는 표준 비동기 처리 방법이 없다. '비동기 런탕미'이라고 하는 크레이트를 설치해 사용해야 한다.
많이 사용되는 비동기 런타임은 다음 2종류가 있다.

- Tokio : 사실상 표준인 비동기 런타임 크레이트로 다양한 환경에서 동작을 보장한다.
- async-std : 모든 표준 API를 비동기화하는 것을 목표로 개발되고 있는 비동기 런타임 크레이트
한 번에 2개 이상의 비동기 런타임 크레이트를 사용하는 것은 추천하지 않는다.
제공하는 API는 서로 다르므로 주의해야 한다.

## 비동기 처리 기본
간단한 비동기 처리를 코드로 만들어보기
async_test라는 프로젝트를 만들고 Cargo.toml에 tokio 크레이트를 추가하기

async_test의 코드에서
1 메인 함수를 정의할 때 \#\[tokio::main] 이라는 속성을 부여했음
이는 해당 함수가 비동기 처리를 한다는 의미임

2 비동기 처리를 준비하는 부분 여기서 say_later 함수를 호출해 비동기로 실행할 처리를 준비한다.

3 프로그램 실행 순서를 확인하기 위한 메시지

4 2에서 준비해둔 비동기 처리를 실행하는 부분
비동기 처리 함수에는 '.await'를 붙여야 실제로 처리가 완료된다.

5 비동기로 실행할 함수이다. 비동기로 실행돼야 하므로 이 함수에도 마찬가지로 async를 붙인다.

흐름만 살펴보면 2에서 비동기 함수를 초기화해두고 대기하다가 3이 처리된 뒤 4에서 await를 이용해 처리를 완료한다.

### 연속으로 비동기 처리를 실행해 반환 값 얻기
러스트의 비동기 처리에서는 비동기 처리를 실행한 결과를 반환 값으로 돌려준다.
여기서는 비동기 처리를 실행해 그 반환 값을 출력하는 프로그램을 만들어본다. 앞에서와 같은 방법으로 'async_longtime' 프로젝트를 만들고 Cargo.toml 파일에 Tokio를 추가한다.

비동기 처리를 반환 값을 출력하는 프로그램을 만들기
```rust
use tokio::time;

#[tokio::main]
async fn main() {
	// 비동기 처리를 연속으로 실행 -1
	for i in 1..=3 {
		println!("#{} 시작", i);
		// 비동기 처리 함수를 실행해 결과를 얻는다. -2
		let s = read_longtime().await;
		println!("{}", s);
		// 비동기 처리는 블록에서도 사용 가능 -3
		let s = async {
			time::sleep(time::Duration::form_secs(1)).await;
			String::from("길게 읽어들이기 완료(block)")
		}.await;
		println!("{}", s);
	}
}

// 시간이 걸리는 함수 -4
async fn read_longtime() -> String {
	time::sleep(time::Duration::from_secs(1)).await;
	String::from("길게 읽어들이기 완료(fn)")
}
```

1 비동기 처리를 연속 3번 실행하게 한다. 
2에서는 비동기 처리 함수 read_longtime을 실행한다.  실행한 결과를 문자열로 얻어 표시한다.
3은 함수가 아니라 async 블록을 따로 만들어서 그 볼록을 비동기 처리하는 부분이다. 러스트에서는 블록도 값을 반환할 수 있으므로 이 비동기 블록을 실행한 결과 역시 표시된다.

4 비동기 처리 함수로 tokio::time::sleep 함수를 사용해 지정한 시간만큼 처리를 대기한다.
이 함수 반환값은 String타입으로, 2에서 이 함수가 실행돼 출력된다.

### 비동기 처리의 병렬 처리
여기서 소개한 내용은 모두 비동기 처리를 직렬로 이용한 것이다. 하지만 비동기 처리를 병렬로도 실행할 수 있다. tokio::spawn 함수나 tokio::join! 매크로를 이용하면 비동기 처리를 병렬로 실행할 수 있다.
다음 프로그램은 지정한 시간 이후 메시지를 표시하는 say_later 함수를 병렬로 실행하는 예다.

```rust
use tokio::time;

// sec초 후 msg를 출력하는 비동기 함수 -1
async fn say_later(sec: u64, msg: &str) {
	time::sleep(time::Duration::from_secs(sec)).await;
	println!("{}: {}", sec, msg);
}

#[tokio::main]
async fn main() {
	// spawn으로 병렬 실행 -2
	tokio::spawn(say_later(3, "그냥 두었다"));
	tokio::spawn(say_later(2, "콧등이 긁혀서 왔다."));
	tokio::spawn(say_later(1, "마실 나갔던 고양이가"));
	// 병렬 실행 완료까지 대기
	time::sleep(time::Duration::from_secs(4)).await;
	println!("-----");
	
	// join!으로 병렬 실행
	tokio::join!(
		say_later(2, "내 구두코도 긁혀 있었다"),
		say_later(3, "정성껏 갈색 약을 발라 주었다."),
		say_later(1, "전날 밤 늦게 귀가한"),
	);
}
```

## 웹페이지의 이미지를 연속으로 다운로드하기
비동기 처리의 구조를 이해했다면 스크래핑 프로그램을 만들어보자.
여기서는 필자가 운영하는 사이트에서 이미지를 다운로드하는 프로그램을 만들어본다.

### 스크래핑 프로젝트 생성
Cargo 명령으로 'scraping_shodou'라는 프로젝트를 만든 다음, Cargo.toml 파일에 비동기 런타임 Tokio, HTTP클라이언트인 reqwest, HTML 분석용 scraper, URL 인코딩용 urlencoding 크레이트를 추가한다.

HTML을 읽어온 뒤 구문 분석을 통해 img요소(이미지가 있는 주소)를 추출하고, 추출된 img 요소를 모두 저장하는 프로그램을 만든다.
```rust
use scraper:;Selector;
use std::{fs::File, io::Write};
use tokio::time;

#[tokio::main]
async fn main() {
	// 특정 제목을 가진 작품 목록을 다운로드
	for title in ["test", "yiy"] {
		download_images(title).await;
	}
}

// 지정한 제목의 이밎지르 ㄹ다운 받는 함수
async fn downlooad_images(title: &str) {
	let shodou_url = "https://uta.pw/shodou";
	// 제목으로 작품 검색
	let url = format!(
		"{}/index.php?title&show&title={}",
		shodou_url,
		urlencoding::encode(title)
	);
	// HTML 취득
	println!("get: {}", url);
	let html = reqwest::get(url)
		.await.unwrap()
		.text().await.unwrap();
	// HTML 구문 분석
	let doc = scraper::Html::parse_document(&html);
	// img 태그 추출
	let sel = Selector::parse(".articles img").unwrap();
	for (i, node) in doc.select(&sel).enumerate() {
		// <img src="***">의 src 속성값 추출
		let src = node.value().attr("str").unwrap();
		let img_url = format!("{}/{}", shodou_url, src);
		println!("{}", img_url);
		// 파일로 이미지를 저장
		let filename = format!("shodou_{}_{}.png", title, i);
		let bytes = reqwest::get(img_url).await.unwrap()
			.bytes().await.unwrap();
		let mut file = File::crate(filename).unwrap();
		file.write_all(&bytes).unwrap();
		// 대기 시간을 설정(중요)
		time::sleep(time::Duration::from_millis(1000)).await;
	}
}
```